{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Brazil’s Oil Production using an ARIMA model and ANP data\n",
    "<b>Luís Eduardo Anunciado Silva</b> - BS Student in Information Technology, Federal University of Rio Grande do Norte<br>\n",
    "\n",
    "<b>Date</b>: November 12, 2018\n",
    "\n",
    "## Introduction\n",
    "My project aims to predict the yearly oil production of a given petroleum reservoir over a given time period, using an <b>ARIMA model</b> for <b>time series forecasting</b> and the [ANP public data base](http://www.anp.gov.br/dados-estatisticos).\n",
    "\n",
    "<p>I also aim to predict the top-10 petroleum reservoir in the Brazil that which will produce the largest amount of oil in the next 10 years.</p>\n",
    "\n",
    "\n",
    "### OBJECTIVE 1: Predicting the Oil Production of a Petroleum Reservoir across a Specified Time Period\n",
    "<p> Using the ANP public data base, we will do the following steps below:</p>\n",
    "\n",
    "<b>Pre-Processing:</b><br>\n",
    "<ol>\n",
    "<li>Build a dataframe with the columns: dt (in DateTime format), well, latitude, longitude.</li>\n",
    "<li>Dropping irrelevant columns and removing rows with NaN values</li>\n",
    "</ol>\n",
    "<b>Processing:</b><br>\n",
    "ARIMA models need the data to be stationary i.e. the data must not exhibit trend and/or seasonality. To identify and remove trend and seasonality, we used the following methods:\n",
    "<ol>\n",
    "<li>Plotting the time series to visually check for trend and seasonality</li>\n",
    "<li>Checking if the histogram of the data fits a Gaussian Curve, and then splitting data into two parts, calculating means and variances and seeing if they vary</li>\n",
    "<li>Calculating the Augmented Dickey-Fuller Test statistic and using the p-value to determine stationarity</li>\n",
    "</ol>\n",
    "If the data was not stationary, we performed <b>differencing</b> to make it stationary.\n",
    "<br><br>\n",
    "<b>Fitting the ARIMA model:</b><br>\n",
    "We performed a grid-search to estimate the best p, q values for the model, for the given data.<br>\n",
    "We then fit the ARIMA model using the calculated p, q values.\n",
    "<br><br>\n",
    "<b>Evaluation:</b><br>\n",
    "We calculated the <b>Mean Squared Error (MSE)</b> to estimate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARMAResults\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipywidgets as widgets\n",
    "import plotly.plotly as py\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from os import walk\n",
    "from unicodedata import normalize\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file with the weels\n",
    "dfs = pd.read_excel('../data/table_of_wells_april_2018.xlsx', sheet_name='Plan1')\n",
    "dfs = dfs.drop({'CADASTRO', 'OPERADOR', 'POCO_OPERADOR', 'ESTADO', 'BACIA', 'BLOCO', 'SIG_CAMPO', 'CAMPO', 'TERRA_MAR', \n",
    "                'POCO_POS_ANP', 'INICIO', 'TERMINO', 'CONCLUSAO', 'TITULARIDADE', 'LATITUDE_BASE_4C', \n",
    "                'LONGITUDE_BASE_4C', 'DATUM_HORIZONTAL', 'TIPO_DE_COORDENADA_DE_BASE', 'DIRECAO', 'PROFUNDIDADE_VERTICAL_M',\n",
    "                'PROFUNDIDADE_SONDADOR_M','PROFUNDIDADE_MEDIDA_M', 'REFERENCIA_DE_PROFUNDIDADE', 'MESA_ROTATIVA', \n",
    "                'COTA_ALTIMETRICA_M','LAMINA_D_AGUA_M', 'DATUM_VERTICAL', 'UNIDADE_ESTRATIGRAFICA', 'GEOLOGIA_GRUPO_FINAL',\n",
    "                'GEOLOGIA_FORMACAO_FINAL', 'GEOLOGIA_MEMBRO_FINAL', 'CDPE', 'AGP', 'PC', 'PAG', 'PERFIS_CONVENCIONAIS',\n",
    "                'DURANTE_PERFURACAO', 'PERFIS_DIGITAIS', 'PERFIS_PROCESSADOS', 'PERFIS_ESPECIAIS', 'AMOSTRA_LATERAL', \n",
    "                'SISMICA', 'TABELA_TEMPO_PROFUNDIDADE', 'DADOS_DIRECIONAIS', 'TESTE_A_CABO', 'CANHONEIO', 'TESTEMUNHO', \n",
    "                'GEOQUIMICA', 'SIG_SONDA', 'NOM_SONDA', 'DHA_ATUALIZACAO'}, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_produtors(dfs):\n",
    "    '''\n",
    "    Filters producting wells in a field\n",
    "    '''\n",
    "    productor = dfs[(dfs['TIPO']==u'Explotatório') & \n",
    "                    (dfs['SITUACAO']=='PRODUZINDO') & \n",
    "                    (dfs['CATEGORIA']=='Desenvolvimento') & \n",
    "                    (dfs['RECLASSIFICACAO']==u'PRODUTOR COMERCIAL DE PETRÓLEO')]\n",
    "    productor.reset_index(inplace=True)\n",
    "    return productor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_injections(dfs):\n",
    "    '''\n",
    "    Filters the injection wells in a field\n",
    "    '''\n",
    "    injector = dfs[(dfs['TIPO']==u'Explotatório') & \n",
    "                   (dfs['SITUACAO']=='INJETANDO') &\n",
    "                   (dfs['CATEGORIA']==u'Injeção') & \n",
    "                   (dfs['RECLASSIFICACAO']==u'INJEÇÃO DE ÁGUA')]\n",
    "    injector.reset_index(inplace=True)\n",
    "    return injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "produtor = get_produtors(dfs)\n",
    "injetor = get_injections(dfs)\n",
    "pai = pd.concat([produtor, injetor])\n",
    "pai.reset_index(inplace=True)\n",
    "pai = pai.drop({'level_0', 'index'}, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pocos = pai[\"POCO\"].tolist()\n",
    "pocos = [poco.lower().replace(' ', '').replace('-', '') for poco in pocos]\n",
    "pocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for (dirpath, dirnames, filenames) in walk('../data/producao-por-poco'):\n",
    "    for filename in filenames:\n",
    "        if filename.startswith('presal') or filename.endswith('presal.xls') or filename.endswith('presal.xlsx'):\n",
    "            files.append('%s/%s' % (dirpath, filename))\n",
    "\n",
    "wells = []\n",
    "for file in sorted(files):\n",
    "    excel_file = pd.read_excel(file)\n",
    "    initial_column = excel_file.columns[0]\n",
    "\n",
    "    period_value = None\n",
    "    well_data = None\n",
    "    production_data = None\n",
    "    try:\n",
    "        if initial_column.startswith('ANP - Agência Nacional do Petroleo'):\n",
    "            data = pd.read_excel(file, skiprows=4, header=[0, 1], index_col=None)\n",
    "\n",
    "            period = data.xs('Período', axis=1, level=0, drop_level=True).iloc[:, 0]\n",
    "            period = period.dropna().unique()\n",
    "            period = period[0].replace('/', '-')\n",
    "\n",
    "            production_col = None\n",
    "            field_col = None\n",
    "            for column in data.columns:\n",
    "                if column[0].startswith('Petróleo (bbl/dia)'):\n",
    "                    production_col = column\n",
    "                if column[0].startswith('Campo'):\n",
    "                    field_col = column\n",
    "            selected_data = data[[('Nome Poço', 'ANP'), field_col, production_col]]\n",
    "\n",
    "            period_value = period\n",
    "            well_data = selected_data[('Nome Poço', 'ANP')].values\n",
    "            field_data = selected_data[field_col].values\n",
    "            production_data = selected_data[production_col].values\n",
    "\n",
    "        elif initial_column.startswith('COD_POCO') or initial_column.startswith('NOM_POCO_ANP'):\n",
    "            data = pd.read_excel(file)\n",
    "\n",
    "            period = data['PERIODO'].dropna().unique()\n",
    "            period = period[0].replace('_', '-')\n",
    "\n",
    "            selected_data = data[['NOM_POCO_ANP', 'NOM_CAMPO', 'OLEO_BBL_DIA']]\n",
    "\n",
    "            well_data = pd.DataFrame(columns=['well', 'production_%s' % period])\n",
    "\n",
    "            period_value = period\n",
    "            well_data = data['NOM_POCO_ANP'].values\n",
    "            field_data = data['NOM_CAMPO'].values\n",
    "            production_data = data['OLEO_BBL_DIA'].values\n",
    "\n",
    "    except Exception as exc:\n",
    "        print('********** Exception **********', exc)\n",
    "\n",
    "    well_df = pd.DataFrame(columns=['well', 'field', '%s-01' % period])\n",
    "    well_df['well'] = well_data\n",
    "    well_df['field'] = field_data\n",
    "    well_df['%s-01' % period] = pd.to_numeric(production_data)\n",
    "\n",
    "    # Remove nan in well index.\n",
    "    well_df = well_df.drop(well_df.loc[well_df.well.isnull()].index, axis=0)\n",
    "    # Remove nan in field index.\n",
    "    well_df = well_df.drop(well_df.loc[well_df.field.isnull()].index, axis=0)\n",
    "    # Remove description index.\n",
    "    well_df = well_df.drop(well_df.loc[well_df.well.map(len) > 50].index, axis=0)\n",
    "\n",
    "    well_df.well = well_df.well.map(str.strip)\n",
    "    well_df.well = well_df.well.map(str.lower)\n",
    "    well_df.field = well_df.field.map(str.strip)\n",
    "    well_df.field = well_df.field.map(str.lower)\n",
    "\n",
    "    def normalize_str(input_str):\n",
    "        return normalize('NFKD', input_str).encode('ascii', 'ignore').decode('utf-8')\n",
    "    well_df.well = well_df.well.map(normalize_str)\n",
    "    well_df.field = well_df.field.map(normalize_str)\n",
    "\n",
    "    def replace_str(input_str):\n",
    "        return input_str.replace(' ', '').replace('-', '')\n",
    "    well_df.well = well_df.well.map(replace_str)\n",
    "    well_df.field = well_df.field.map(replace_str)\n",
    "\n",
    "    well_df['index'] = well_df.apply(lambda row: '%s' % (row['well']), axis=1)\n",
    "\n",
    "    well_df = well_df.drop('well', axis=1)\n",
    "    well_df = well_df.drop('field', axis=1)\n",
    "    well_df = well_df.set_index('index')\n",
    "\n",
    "    well_df = well_df[~well_df.index.duplicated(keep='first')]\n",
    "\n",
    "    wells.append(well_df)\n",
    "\n",
    "salt_df = pd.concat(wells, axis=1).dropna()\n",
    "salt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_time = salt_df.columns.values.tolist()\n",
    "salt_wells = salt_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['dt', 'oil', 'well'])\n",
    "for well in salt_wells:\n",
    "    for time in salt_time:\n",
    "        s = pd.Series([time, salt_df.loc[well, time], well], index=['dt', 'oil', 'well'])\n",
    "        df = df.append(s,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert first column to DateTime format\n",
    "df['dt'] = pd.to_datetime(df['dt'])\n",
    "\n",
    "# set first column (dt) as the index column\n",
    "df.index = df['dt']\n",
    "del df['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check stationarity in time series data of a given well\n",
    "\n",
    "def check_stationarity(well_df):\n",
    "    # method1: plot the time series to check for trend and seasonality\n",
    "    well_df.plot(figsize=(10, 10))\n",
    "    \n",
    "    # method 2: check if histogram fits a Gaussian Curve, then split data into two parts, calculate means and variances and see if they vary\n",
    "    well_df.hist(figsize=(10, 10))\n",
    "    plt.show()\n",
    "    \n",
    "    X = well_df[\"oil\"].values\n",
    "    split = int(len(X) / 2)\n",
    "    X1, X2 = X[0:split], X[split:]\n",
    "    mean1, mean2 = X1.mean(), X2.mean()\n",
    "    var1, var2 = X1.var(), X2.var()\n",
    "    print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
    "    print('variance1=%f, variance2=%f' % (var1, var2))\n",
    "    \n",
    "    # if corresponding means and variances differ slightly (by less than 10), we consider that the time series might be stationary\n",
    "    if (abs(mean1-mean2) <= 10 and abs(var1-var2) <= 10):\n",
    "        print(\"Time Series may be Stationary, since means and variances vary only slightly.\\n\")\n",
    "    else:\n",
    "        print(\"Time Series may NOT be Stationary, since means and variances vary significantly.\\n\")\n",
    "        \n",
    "    # method3: statistical test (Augmented Dickey-Fuller statistic)\n",
    "    print(\"Performing Augmented Dickey-Fuller Test to confirm stationarity...\")\n",
    "    \n",
    "    result = adfuller(X)\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    \n",
    "    p = result[1]\n",
    "    if (p > 0.05):\n",
    "        print(\"Time Series is NOT Stationary, since p-value > 0.05\")\n",
    "        well_df = well_df.diff()  # differencing to make data stationary\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Time Series is Stationary, since p-value <= 0.05\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check stationarity for data of a specific city entered by the user\n",
    "\n",
    "well_drop_down_menu = widgets.Dropdown(\n",
    "    options=sorted(list(salt_wells)),\n",
    "    value='3brsa1017drjs',\n",
    "    description='well:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "well_drop_down_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_well = well_drop_down_menu.value\n",
    "well_df = df[df.well == chosen_well].drop(\"well\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Stationarity Check for %s\" % chosen_well)\n",
    "is_stationary = check_stationarity(well_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ACF and PACF plots\n",
    "\n",
    "plot_acf(well_df)\n",
    "plot_pacf(well_df)\n",
    "plt.show()\n",
    "\n",
    "# setting d value for ARIMA model\n",
    "if (is_stationary==True):\n",
    "    d = 0\n",
    "else:\n",
    "    d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_range = q_range = list(range(0,3))  # taking values from 0 to 2\n",
    "\n",
    "aic_values = []\n",
    "bic_values = []\n",
    "pq_values = []\n",
    "\n",
    "for p in p_range:\n",
    "    for q in q_range:\n",
    "        try:\n",
    "            model = ARIMA(well_df, order=(p, d, q))\n",
    "            results = model.fit(disp=-1)\n",
    "            aic_values.append(ARMAResults.aic(results))\n",
    "            bic_values.append(ARMAResults.bic(results))\n",
    "            pq_values.append((p, q))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "best_pq = pq_values[aic_values.index(min(aic_values))]  # (p,q) corresponding to lowest AIC score\n",
    "print(\"(p,q) corresponding to lowest AIC score: \", best_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting an ARIMA model with chosen p, d, q values and calculating the mean squared error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "arima_model = ARIMA(well_df, order=(best_pq[0], 0, best_pq[1])).fit()\n",
    "predictions = arima_model.predict(start=0, end=len(well_df)-1)\n",
    "\n",
    "mse = mean_squared_error(list(well_df.oil), list(predictions))\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "mae = mean_absolute_error(list(well_df.oil), list(predictions))\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing first 100 predictions with actual values\n",
    "\n",
    "plt.figure(figsize=(7.5,7.5))\n",
    "plt.plot(list(well_df.oil)[:100], label=\"Actual\")\n",
    "plt.plot(list(predictions)[:100], 'r', label=\"Predicted\")\n",
    "\n",
    "plt.xlabel(\"Time (in Months)\")\n",
    "plt.ylabel(\"Oil (b/day)\")\n",
    "plt.title(\"Actual and Predicted Oil Values\")\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(1.45, 0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE 2: Top-10 Wells in the Brazil with Maximum Production of Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = []  # stores temperature change for cities\n",
    "avg_2013 = []  # stores average of 2013 temperature for each city\n",
    "avg_2023 = []  # stores average of 2023 temperature for each city\n",
    "\n",
    "for each_well in set(salt_wells):\n",
    "    new_well_df = df[df.well == each_well].drop(\"well\", 1)  # new df for each city\n",
    "    new_well_df_mean = new_well_df.resample(\"A\").mean()  # stores yearly mean temperature values for city\n",
    "    new_well_df_mean = new_well_df_mean.dropna()\n",
    "    last_year_average = new_well_df_mean['oil'][-1]  # average of last year temperature for comparison later\n",
    "    avg_2013.append(last_year_average)\n",
    "    \n",
    "    # making predictions for city for next 10 years\n",
    "    p_range = q_range = [i for i in range(0,3)]  # taking values from 0 to 2\n",
    "\n",
    "    aic_values = []\n",
    "    bic_values = []\n",
    "    pq_values = []\n",
    "\n",
    "    for p in p_range:\n",
    "        for q in q_range:\n",
    "            try:\n",
    "                model = ARIMA(new_well_df, order=(p, 0, q))\n",
    "                results = model.fit(disp=-1)\n",
    "                aic_values.append(ARMAResults.aic(results))\n",
    "                bic_values.append(ARMAResults.bic(results))\n",
    "                pq_values.append((p, q))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    best_pq = pq_values[aic_values.index(min(aic_values))]  # (p,q) corresponding to lowest AIC score\n",
    "    \n",
    "    arima_model = ARIMA(new_well_df, order=(best_pq[0], 0, best_pq[1])).fit()\n",
    "    \n",
    "    # make prediction for next 10 years using 120 steps\n",
    "    out_of_sample_forecast = arima_model.forecast(steps=120)[0]\n",
    "    average_after_10_years = np.mean(out_of_sample_forecast[-9:])  # average of 10th year's values (after 10 years) i.e. average of last 9 values (Jan-Sep because 2013 values end at September)\n",
    "    avg_2023.append(average_after_10_years)\n",
    "    \n",
    "    changes.append(abs(last_year_average - average_after_10_years))\n",
    "    \n",
    "    top_10_changes_indices = sorted(range(len(changes)), key=lambda i: changes[i], reverse=True)[:10]\n",
    "    top_10_well = [salt_wells[x] for x in top_10_changes_indices]\n",
    "    top_10_well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folium_map(lat, lot, zfact):\n",
    "    '''\n",
    "    Cria um objeto Folium.Map do tipo OpenStreetMap centrado em (lat,lot) com nível de zoom zfact\n",
    "    '''\n",
    "    import folium\n",
    "    tiles = 'http://server.arcgisonline.com/ArcGIS/rest/services/NatGeo_World_Map/MapServer/tile/{z}/{y}/{x}'\n",
    "    attr = ('Tiles &copy; Esri &mdash; Sources: GEBCO, NOAA, CHS, OSU, UNH, CSUMB, National Geographic, DeLorme, NAVTEQ, and Esri')\n",
    "    m = folium.Map(location=[lat,lot], \n",
    "            tiles=tiles,\n",
    "            attr=attr,\n",
    "            zoom_start=zfact)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_folium_map(-22.0,-40.0,8)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pocos_mapa(mapa, pocos, cor, kind=1, nome_grupo=u'default'):\n",
    "    if kind != 1 and kind != 2:\n",
    "        print(\"Erro: Tipo de marcação no mapa indisponível!\")\n",
    "        return False\n",
    "    else:\n",
    "        pocos_len = pocos.shape[0]\n",
    "        grupo = folium.FeatureGroup(nome_grupo)\n",
    "        for i in range(pocos_len):\n",
    "            lat, lont = float(pocos['LATITUDE_BASE_DD'][i].replace(\",\",\".\")), float(pocos['LONGITUDE_BASE_DD'][i].replace(\",\",\".\"))\n",
    "            if kind==1:\n",
    "                folium.Marker(\n",
    "                    location=[lat, lont],\n",
    "                    popup=pocos['POCO'][i],\n",
    "                    icon=folium.Icon(color=cor),\n",
    "                    ).add_to(grupo)\n",
    "            if kind==2:\n",
    "                folium.Circle(\n",
    "                    location=[lat, lont],\n",
    "                    popup=pocos['POCO'][i],\n",
    "                    radius=15,\n",
    "                    color='red',\n",
    "                    fill=True,\n",
    "                    fill_color='crimson'\n",
    "                    ).add_to(grupo)\n",
    "            grupo.add_to(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pai2 = pai\n",
    "\n",
    "for index, row in pai2.iterrows():\n",
    "    if row['POCO'].lower().replace(' ', '').replace('-', '') in top_10_well:\n",
    "        print(row['POCO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pocos_mapa(\n",
    "    m,\n",
    "    pai2,\n",
    "    'red'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we:\n",
    "\n",
    "<ul>\n",
    "<li>Forecasted the temperature of a given city over a given period of time</li>\n",
    "<li>Predicted the top-10 cities in the US which will experience the most temperature change from 2013-2013.</li>\n",
    "<li>Analyzed the correlation between pollution levels and temperature, as well as the correlation between Greenhouse gas emissions and temperature, which helped us identify the Greenhouse Gas that has and will have the most impact on temperature change.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refference\n",
    "\n",
    "<ul>\n",
    "<li>Forecasted the temperature of a given city over a given period of time</li>\n",
    "<li>Predicted the top-10 cities in the US which will experience the most temperature change from 2013-2013.</li>\n",
    "<li>Analyzed the correlation between pollution levels and temperature, as well as the correlation between Greenhouse gas emissions and temperature, which helped us identify the Greenhouse Gas that has and will have the most impact on temperature change.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
